"""
ç¶²åŸŸè®Šå½¢æ”»æ“Šæª¢æ¸¬æ¨¡çµ„
ç”¨æ–¼æª¢æ¸¬æ¨¡ä»¿ç™½åå–®ç¶²åŸŸçš„å¯ç–‘ç¶²å€
"""

import re
from urllib.parse import urlparse

def detect_domain_spoofing(url_or_message, safe_domains):
    """
    æª¢æ¸¬ç¶²åŸŸè®Šå½¢æ”»æ“Š - è­˜åˆ¥æ¨¡ä»¿ç™½åå–®ç¶²åŸŸçš„å¯ç–‘ç¶²å€
    
    Args:
        url_or_message: è¦æª¢æ¸¬çš„URLæˆ–åŒ…å«URLçš„è¨Šæ¯
        safe_domains: ç™½åå–®ç¶²åŸŸå­—å…¸
        
    Returns:
        dict: {
            'is_spoofed': bool,  # æ˜¯å¦ç‚ºè®Šå½¢ç¶²åŸŸ
            'original_domain': str,  # è¢«æ¨¡ä»¿çš„åŸå§‹ç¶²åŸŸ
            'spoofed_domain': str,  # å¯ç–‘çš„è®Šå½¢ç¶²åŸŸ
            'spoofing_type': str,  # è®Šå½¢é¡å‹
            'risk_explanation': str  # é¢¨éšªèªªæ˜
        }
    """
    # æå–URL
    url_pattern = re.compile(r'https?://[^\s]+|www\.[^\s]+|[a-zA-Z0-9][a-zA-Z0-9-]*\.[a-zA-Z]{2,}[^\s]*')
    urls = url_pattern.findall(url_or_message)
    
    if not urls:
        return {'is_spoofed': False}
    
    for url in urls:
        # æ¨™æº–åŒ–URL
        if not url.startswith(('http://', 'https://')):
            if url.startswith('www.'):
                url = 'https://' + url
            else:
                url = 'https://' + url
        
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            # ç§»é™¤ www. å‰ç¶´é€²è¡Œæ¯”è¼ƒ
            if domain.startswith('www.'):
                domain = domain[4:]
            
            # æª¢æŸ¥æ¯å€‹ç™½åå–®ç¶²åŸŸ
            for safe_domain in safe_domains.keys():
                safe_domain_lower = safe_domain.lower()
                
                # è·³éå®Œå…¨ç›¸åŒçš„ç¶²åŸŸï¼ˆé€™æ˜¯æ­£å¸¸çš„ï¼‰
                if domain == safe_domain_lower:
                    continue
                
                # è·³éåˆæ³•çš„å­ç¶²åŸŸï¼ˆä¾‹å¦‚ mail.google.com, maps.google.comï¼‰
                if domain.endswith('.' + safe_domain_lower):
                    continue
                
                # æª¢æ¸¬å„ç¨®è®Šå½¢æ‰‹æ³•
                spoofing_detected = False
                spoofing_type = ""
                
                # 1. å­—å…ƒæ›¿æ›æ”»æ“Š (ä¾‹å¦‚ google.com -> goog1e.com, googlĞµ.com)
                if _is_character_substitution(domain, safe_domain_lower):
                    spoofing_detected = True
                    spoofing_type = "å­—å…ƒæ›¿æ›"
                
                # 2. æ’å…¥é¡å¤–å­—å…ƒ (ä¾‹å¦‚ google.com -> google-tw.com, google.com.tw)
                elif _is_character_insertion(domain, safe_domain_lower):
                    spoofing_detected = True
                    spoofing_type = "æ’å…¥é¡å¤–å­—å…ƒ"
                
                # 3. ç¶²åŸŸå¾Œç¶´è®Šå½¢ (ä¾‹å¦‚ google.com -> google.com.tw, google-tw.com)
                elif _is_domain_suffix_spoofing(domain, safe_domain_lower):
                    spoofing_detected = True
                    spoofing_type = "ç¶²åŸŸå¾Œç¶´è®Šå½¢"
                
                # 4. åŒéŸ³å­—æˆ–ç›¸ä¼¼å­—æ”»æ“Š (ä¾‹å¦‚ google.com -> goog1e.com)
                elif _is_homograph_attack(domain, safe_domain_lower):
                    spoofing_detected = True
                    spoofing_type = "ç›¸ä¼¼å­—å…ƒæ”»æ“Š"
                
                if spoofing_detected:
                    site_description = safe_domains.get(safe_domain, "çŸ¥åç¶²ç«™")
                    return {
                        'is_spoofed': True,
                        'original_domain': safe_domain,
                        'spoofed_domain': domain,
                        'spoofing_type': spoofing_type,
                        'risk_explanation': f"âš ï¸ é«˜é¢¨éšªè­¦å‘Šï¼\n\né€™å€‹ç¶²å€ {domain} ç–‘ä¼¼æ¨¡ä»¿æ­£ç‰Œçš„ {safe_domain} ({site_description})ã€‚\n\nè©é¨™é›†åœ˜å¸¸ç”¨é€™ç¨®æ‰‹æ³•è£½ä½œå‡ç¶²ç«™ä¾†é¨™å–å€‹äººè³‡æ–™æˆ–ä¿¡ç”¨å¡è³‡è¨Šã€‚\n\nğŸš¨ åƒè¬ä¸è¦åœ¨é€™å€‹ç¶²ç«™è¼¸å…¥ä»»ä½•å€‹äººè³‡æ–™ã€å¯†ç¢¼æˆ–ä¿¡ç”¨å¡è™Ÿç¢¼ï¼"
                    }
        
        except Exception as e:
            # URLè§£æå¤±æ•—ï¼Œç¹¼çºŒæª¢æŸ¥ä¸‹ä¸€å€‹
            continue
    
    return {'is_spoofed': False}

def _is_character_substitution(suspicious_domain, safe_domain):
    """æª¢æ¸¬å­—å…ƒæ›¿æ›æ”»æ“Š"""
    # è¨ˆç®—ç·¨è¼¯è·é›¢ï¼ˆLevenshtein distanceï¼‰
    def levenshtein_distance(s1, s2):
        if len(s1) < len(s2):
            return levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    # å¦‚æœç·¨è¼¯è·é›¢å¾ˆå°ä¸”é•·åº¦ç›¸è¿‘ï¼Œå¯èƒ½æ˜¯å­—å…ƒæ›¿æ›
    distance = levenshtein_distance(suspicious_domain, safe_domain)
    length_diff = abs(len(suspicious_domain) - len(safe_domain))
    
    return distance <= 2 and length_diff <= 1

def _is_character_insertion(suspicious_domain, safe_domain):
    """æª¢æ¸¬å­—å…ƒæ’å…¥æ”»æ“Š"""
    # å¸¸è¦‹çš„æ’å…¥æ¨¡å¼
    insertion_patterns = [
        f"{safe_domain.split('.')[0]}-tw.{'.'.join(safe_domain.split('.')[1:])}",  # google.com -> google-tw.com
        f"{safe_domain.split('.')[0]}-taiwan.{'.'.join(safe_domain.split('.')[1:])}",  # google.com -> google-taiwan.com
        f"{safe_domain}.tw",  # google.com -> google.com.tw
        f"tw.{safe_domain}",  # google.com -> tw.google.com
        f"taiwan.{safe_domain}",  # google.com -> taiwan.google.com
    ]
    
    return suspicious_domain in insertion_patterns

def _is_domain_suffix_spoofing(suspicious_domain, safe_domain):
    """æª¢æ¸¬ç¶²åŸŸå¾Œç¶´è®Šå½¢"""
    # æª¢æŸ¥æ˜¯å¦åŒ…å«å®Œæ•´çš„å®‰å…¨ç¶²åŸŸä½œç‚ºå‰ç¶´
    if suspicious_domain.startswith(safe_domain + '.'):
        # ä¾‹å¦‚ cht.com.tw.fake.com åŒ…å« cht.com.tw.
        return True
    
    safe_base = safe_domain.split('.')[0]  # ä¾‹å¦‚å¾ google.com å–å¾— google
    suspicious_base = suspicious_domain.split('.')[0]  # ä¾‹å¦‚å¾ google-tw.com å–å¾— google-tw
    
    # æª¢æŸ¥æ˜¯å¦åœ¨åŸºç¤ç¶²åŸŸåç¨±å¾ŒåŠ äº†é¡å¤–å­—å…ƒ
    if suspicious_base.startswith(safe_base) and len(suspicious_base) > len(safe_base):
        added_part = suspicious_base[len(safe_base):]
        # å¸¸è¦‹çš„æ·»åŠ æ¨¡å¼
        common_additions = ['-tw', '-taiwan', '-official', '-secure', '-login', '-bank', '-pay']
        return any(added_part.startswith(addition) for addition in common_additions)
    
    return False

def _is_homograph_attack(suspicious_domain, safe_domain):
    """æª¢æ¸¬åŒéŸ³å­—æˆ–ç›¸ä¼¼å­—å…ƒæ”»æ“Š"""
    # å¸¸è¦‹çš„å­—å…ƒæ›¿æ›å°æ‡‰
    homograph_map = {
        'o': ['0', 'Î¿', 'Ğ¾'],  # è‹±æ–‡o, æ•¸å­—0, å¸Œè‡˜å­—æ¯omicron, ä¿„æ–‡o
        'a': ['Ğ°', 'Î±'],  # è‹±æ–‡a, ä¿„æ–‡a, å¸Œè‡˜å­—æ¯alpha
        'e': ['Ğµ', 'Îµ'],  # è‹±æ–‡e, ä¿„æ–‡e, å¸Œè‡˜å­—æ¯epsilon
        'i': ['1', 'l', 'Ñ–', 'Î¹'],  # è‹±æ–‡i, æ•¸å­—1, è‹±æ–‡l, ä¿„æ–‡i, å¸Œè‡˜å­—æ¯iota
        'l': ['1', 'i', 'Î¹'],  # è‹±æ–‡l, æ•¸å­—1, è‹±æ–‡i, å¸Œè‡˜å­—æ¯iota
        'n': ['Î·'],  # è‹±æ–‡n, å¸Œè‡˜å­—æ¯eta
        'p': ['Ï'],  # è‹±æ–‡p, å¸Œè‡˜å­—æ¯rho
        'c': ['Ñ'],  # è‹±æ–‡c, ä¿„æ–‡c
        'x': ['Ñ…'],  # è‹±æ–‡x, ä¿„æ–‡x
    }
    
    # ç”Ÿæˆå¯èƒ½çš„åŒéŸ³å­—è®Šå½¢
    def generate_homograph_variants(domain):
        variants = [domain]
        for char, replacements in homograph_map.items():
            new_variants = []
            for variant in variants:
                for replacement in replacements:
                    new_variants.append(variant.replace(char, replacement))
            variants.extend(new_variants)
        return variants
    
    safe_variants = generate_homograph_variants(safe_domain)
    return suspicious_domain in safe_variants 